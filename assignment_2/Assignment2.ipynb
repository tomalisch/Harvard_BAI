{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMd5XFEMpmkG"
   },
   "source": [
    "<html>\n",
    "<body>\n",
    "    <center> \n",
    "        <h1><u>Assignment 2</u></h1>\n",
    "        <h3> Customizing the code to run your own experiments</h3>\n",
    "    </center>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvQQRsLvpmkM"
   },
   "source": [
    "### Learning Outcomes\n",
    "\n",
    "In assignment 1 we covered two things mainly - (1) introducing you to a pipeline for coding ML projects - the data loader, loading models, calculating losses and using an optimizer to update the weights of the model (i.e. learning  the weights of the model). But we didn't look into the nuts and bolts of these pieces. Assignment 2 will delve deeper into these pieces and learn how to customize them.\n",
    "\n",
    "There are two major components:\n",
    "\n",
    "- Learning how to load your own data.\n",
    "- Writing a custom CNN model to classify these images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIBmTQh_pmkN"
   },
   "source": [
    "### Please specify your Name, Email ID and forked repository url here:\n",
    "- Name: Tom Alisch \n",
    "- Email: talisch@g.harvard.edu\n",
    "- Link to your forked github repository: https://github.com/tomalisch/Harvard_BAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JLZ79lZUpmkN"
   },
   "outputs": [],
   "source": [
    "### General libraries useful for python ###\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1613522866738,
     "user": {
      "displayName": "Spandan Madan",
      "photoUrl": "",
      "userId": "18305993989659529139"
     },
     "user_tz": 300
    },
    "id": "NBYo9vxspmkN",
    "outputId": "14613e67-2d34-4f1c-ea91-356c893495c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your github directory is :C:/Users/alisc/Documents/GitHub/Harvard_BAI\n"
     ]
    }
   ],
   "source": [
    "### Finding where you clone your repo, so that code upstream paths can be specified programmatically ####\n",
    "git_dir = 'C:/Users/alisc/Documents/GitHub/Harvard_BAI'\n",
    "print('Your github directory is :%s'%git_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vSIu5jATTZn7"
   },
   "outputs": [],
   "source": [
    "assignment_2_folder = \"%s/assignment_2\"%git_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qBHqiYHSMY9t"
   },
   "outputs": [],
   "source": [
    "os.chdir(assignment_2_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "L2vk8XYjpmkO"
   },
   "outputs": [],
   "source": [
    "### Libraries for visualizing our results and data ###\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "stYTIO0EpmkP",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Import PyTorch and its components ###\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pw2HumdXpmkP"
   },
   "source": [
    "#### Let's load our flexible code-base which you will build on for your research projects in future assignments.\n",
    "\n",
    "Like assignment 1, we are loading in our code-base for convenient dataloading/model loading etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1613522873639,
     "user": {
      "displayName": "Spandan Madan",
      "photoUrl": "",
      "userId": "18305993989659529139"
     },
     "user_tz": 300
    },
    "id": "5bU3tVqsFRT_",
    "outputId": "228a8aaf-3844-43b9-f8d3-3d87e227e09e"
   },
   "outputs": [],
   "source": [
    "### Making helper code under the folder res available. This includes loaders, models, etc. ###\n",
    "sys.path.append('%s/res/'%git_dir)\n",
    "from models.models import get_model\n",
    "from loader.loader import get_loader\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAVtuHh0pmkQ"
   },
   "source": [
    "#### See those paths printed above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MV_MPAjxpmkQ"
   },
   "source": [
    "As earlier, models i.e. architectures are being loaded from `res/models`. In this assignment we will be using the ResNet18 architecture, which is being loaded from the script `res/ResNet.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgpN78WapmkR"
   },
   "source": [
    "### Specifying settings/hyperparameters for our code below ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAONDMnApmkR"
   },
   "source": [
    "By changing above, different experiments can be run. For example, you can specify which model architecture to load, which dataset you will be loading, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_config = {}\n",
    "wandb_config['batch_size'] = 10\n",
    "wandb_config['base_lr'] = 0.01\n",
    "wandb_config['model_arch'] = 'ResNet18'\n",
    "wandb_config['num_classes'] = 10\n",
    "wandb_config['run_name'] = 'assignment_2'\n",
    "\n",
    "### If you are using a CPU, please set wandb_config['use_gpu'] = 0 below. However, if you are using a GPU, leave it unchanged ####\n",
    "wandb_config['use_gpu'] = 1\n",
    "\n",
    "wandb_config['num_epochs'] = 2\n",
    "wandb_config['git_dir'] = git_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdgYVaVppmkR"
   },
   "source": [
    "### Data Loading ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSeW7ZgopmkS"
   },
   "source": [
    "The most common task many of you will be doing in your projects will be running a script on a new dataset. In PyTorch this is done using data loaders, and it is extremely important to understand this works. In next assignment, you will be writing your own dataloader. For now, we only expose you to basic data loading which for the MNIST dataset for which PyTorch provides easy functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fROn07mNpmkS"
   },
   "source": [
    "### Let's load our own custom dataset. We will be using the Cats vs Dogs dataset from Kaggle.com\n",
    "\n",
    "Download the data from https://www.kaggle.com/c/dogs-vs-cats/data.\n",
    "\n",
    "Store it in `assignment_2/data/` and unzip the files.\n",
    "\n",
    "So, the train images should be inside the directory: Harvard_BAI/assignment_2/data/dogs-vs-cats/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_f4QqhkpmkT"
   },
   "source": [
    "Data Transforms tell PyTorch how to pre-process your data. Recall that images are stored with values between 0-255 usually. One very common pre-processing for images is to normalize to be 0 mean and 1 standard deviation. This pre-processing makes the task easier for neural networks. There are many, many kinds of normalization in deep learning, the most basic one being those imposed on the image data while loading it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faqQRpGuTLsd"
   },
   "source": [
    "### Let's create a file list of all our image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dDQyNNj627eo"
   },
   "outputs": [],
   "source": [
    "train_folder_files = os.listdir('%s/data/dogs-vs-cats/train/'%assignment_2_folder)\n",
    "random.shuffle(train_folder_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nKleAnDzI94c"
   },
   "outputs": [],
   "source": [
    "total_points = len(train_folder_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xHkSt_fgJF3n"
   },
   "outputs": [],
   "source": [
    "train_files = train_folder_files[:int(0.8*total_points)]\n",
    "val_files = train_folder_files[int(0.8*total_points):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0sTMxWIXTODZ"
   },
   "outputs": [],
   "source": [
    "test_files = os.listdir('%s/data/dogs-vs-cats/test1/'%assignment_2_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Y93LkDld3J2X"
   },
   "outputs": [],
   "source": [
    "labels_dictionary = {}\n",
    "with open('data/train_file_list.txt','w') as F:\n",
    "    for t in train_files:\n",
    "        file_path = '%s/data/dogs-vs-cats/train/%s'%(assignment_2_folder, t)\n",
    "        if 'dog' in t:\n",
    "            labels_dictionary[file_path] = 0\n",
    "            print(file_path, file = F)\n",
    "        elif 'cat' in t:\n",
    "            labels_dictionary[file_path] = 1\n",
    "            print(file_path, file = F)\n",
    "        \n",
    "\n",
    "with open('data/val_file_list.txt','w') as F:\n",
    "    for t in train_files:\n",
    "        file_path = '%s/data/dogs-vs-cats/train/%s'%(assignment_2_folder, t)\n",
    "        if 'dog' in t:\n",
    "            labels_dictionary[file_path] = 0\n",
    "            print(file_path, file = F)\n",
    "        elif 'cat' in t:\n",
    "            labels_dictionary[file_path] = 1\n",
    "            print(file_path, file = F)\n",
    "\n",
    "with open('data/test_file_list.txt','w') as F:\n",
    "    for t in test_files:\n",
    "        file_path = '%s/data/dogs-vs-cats/test1/%s'%(assignment_2_folder, t)\n",
    "        labels_dictionary[file_path] = -1\n",
    "        print(file_path, file = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcMXyppD-vsg"
   },
   "source": [
    "Above, you should see 0 if it's a dog, 1 if it's a cat, and -1 if it's an image for which we don't have a label (test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tz0i23ogApQF"
   },
   "outputs": [],
   "source": [
    "with open('%s/data/labels_dictionary.p'%assignment_2_folder, 'wb') as F:\n",
    "    pickle.dump(labels_dictionary, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-IM8j6vKGTg"
   },
   "source": [
    "# Using our custom data-loader. \n",
    "\n",
    "Our data-loader is called cats_dogs_loader which is in `res/loader/cats_dogs_loader`. Read this file carefully! It's extremely important to understand this. \n",
    "\n",
    "\n",
    "An overview to help you understand the file: when you first call get_loader() below, you only tell python that you will be creating objects from the file cats_dogs_loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GMYXrJgn74-P"
   },
   "outputs": [],
   "source": [
    "file_list_loader = get_loader('cats_dogs_loader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BwVYrw4va5OL"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "     'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuzzYUmjpmkT"
   },
   "source": [
    "In assignment 1 we just used `torchvision.datasets.MNIST` to load MNIST data. But now we, can't rely on that function as we have a custom dataset. Here we learn how to handle such custom data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1peYCIkede03"
   },
   "source": [
    "We use our custom file_list_loader to load data that we have downloaded and unzipped. Above, we created file lists which contain paths to our train, validation and test datasets, here we will pass these file lists to the file_list_loader.\n",
    "\n",
    "### Open the file cats_dogs_loaders.py, you will see a class FileListFolder.\n",
    "\n",
    "In the file loader.py we load this class FileListFolder in the function get_loader. So, when we run get_loader(\"cats_dogs_loader\") above, what is returned is the class FileListFolder. So, now when we run file_list_folder(), the arguments inside are passed to the class FileListFolder as described in cats_dogs_loader.py.\n",
    "\n",
    "Thus, the first time you pass this, the __init__ function is run i.e. an object of that class is initialized. As you can see, the __init__ function in cats_dogs_loader.py requires 3 attributes - a file list, a labels dictionary and a pytorch transform object. To create a new data loader, we need to create a file lie cats_dogs_loder.py and make necessary changes to it.\n",
    "\n",
    "\n",
    "The file lists contain paths to train/val/test files. The labels dictionary is a dictionary storing category numbers for each of these files, and the transforms are the pre-processing pytorch does to our loaded images before starting trainig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JO9Oy04kITzd"
   },
   "outputs": [],
   "source": [
    "dsets = {}\n",
    "dsets['train'] = file_list_loader('%s/data/train_file_list.txt'%assignment_2_folder, '%s/data/labels_dictionary.p'%assignment_2_folder, data_transforms['train'])\n",
    "dsets['val'] = file_list_loader('%s/data/val_file_list.txt'%assignment_2_folder, '%s/data/labels_dictionary.p'%assignment_2_folder, data_transforms['val'])\n",
    "dsets['test'] = file_list_loader('%s/data/test_file_list.txt'%assignment_2_folder, '%s/data/labels_dictionary.p'%assignment_2_folder, data_transforms['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kMPWCW6jCHFh"
   },
   "outputs": [],
   "source": [
    "### Above, we created datasets. Now, we will pass them into pytorch's inbuild dataloaders, \n",
    "### these will help us load batches of data for training.\n",
    "dset_loaders = {}\n",
    "dset_loaders['train'] = torch.utils.data.DataLoader(dsets['train'], batch_size=wandb_config['batch_size'], shuffle = True, num_workers=2,drop_last=False)\n",
    "dset_loaders['val'] = torch.utils.data.DataLoader(dsets['val'], batch_size=wandb_config['batch_size'], shuffle = False, num_workers=2,drop_last=False)\n",
    "dset_loaders['test'] = torch.utils.data.DataLoader(dsets['test'], batch_size=wandb_config['batch_size'], shuffle = True, num_workers=2,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PEDTP2GnCUOC"
   },
   "outputs": [],
   "source": [
    "data_sizes = {}\n",
    "data_sizes['train'] = len(dsets['train'])\n",
    "data_sizes['val'] = len(dsets['val'])\n",
    "data_sizes['test'] = len(dsets['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xonOzJQeO0Q"
   },
   "source": [
    "## Loading model using PyTorch's in-built methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-BtzO9dveSaF"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKPyscMfebAw"
   },
   "source": [
    "Pytorch makes it easy to load many standard models like resnet18 above. There are many more available. You can see the list here -  https://github.com/pytorch/vision/tree/master/torchvision/models.\n",
    "\n",
    "But, what if you want to build your own custom model? Below, we see how to load your custom models which you would write, and store in the `res/models/` folder. For current purposes, I have created a copy of the popular ResNet architectures in the folder which we will be loading and using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-39kO7WjpmkU"
   },
   "source": [
    "### We will use the `get_model` functionality to load a CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ofvHKm47MxST"
   },
   "outputs": [],
   "source": [
    "### Since we pass ResNet18 below, this will get relayed to \n",
    "### the get_model function loaded from models.py. \n",
    "### As you can see, that would load the resnet18 model from the file\n",
    "### ResNet18.py at `res/models/`.\n",
    "model = get_model('ResNet18', 1000)\n",
    "in_filters = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=in_filters, out_features=2)\n",
    "model.cuda();\n",
    "\n",
    "\n",
    "## above, we first load the ResNet18 architecture, starting with weights from ImageNet.\n",
    "## that's why we have pre-training = True. But then, our task does not have 1000 classes, \n",
    "## but only 2 classes (dogs and cats), so we replace the final layer of our model\n",
    "## with a Linear layer with out_features = 2\n",
    "## finally, we move our model to the GPU with .cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFXtAksGbif_"
   },
   "source": [
    "# Complete the code below to load a resnet34 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "93238d035cce43558481cf65d0466943",
      "a84f4fc4ff2346c382192a8ca39547e6",
      "ab796b059455467285f8baae800aed52",
      "930e6bffa5924460bc99bad111084a25",
      "08216b2975a0470c99039349d96a7744",
      "2d28b0b3ca4a4ad996eb5ed3f515e9cb",
      "ace34fab07284f2a83d5c7a0844605c6",
      "0dd6daa2fe824b64a8a49d69b3ba7a16"
     ]
    },
    "executionInfo": {
     "elapsed": 1458,
     "status": "ok",
     "timestamp": 1613523030391,
     "user": {
      "displayName": "Spandan Madan",
      "photoUrl": "",
      "userId": "18305993989659529139"
     },
     "user_tz": 300
    },
    "id": "ZXhnbYKQbhG1",
    "outputId": "ba01cb06-e717-4d0b-a4d8-c7dbc12874f8"
   },
   "outputs": [],
   "source": [
    "### Above we loaded a ResNet18 model. \n",
    "### Read the file `res/models/models.py` and decide what you \n",
    "### should fill below to load the ResNet34 model instead.\n",
    "\n",
    "model = get_model('ResNet34', 1000)\n",
    "in_filters = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=in_filters, out_features=wandb_config['num_classes'])\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdfV0B5ob9vr"
   },
   "source": [
    "# What changes would you need to make to load a resnet50 model?\n",
    "\n",
    "As you can see there is a function called resnet50 in the file ResNet.py in `res/models/ResNet.py` but this function is not loaded in models.py. So, we would need to add another if statement to load resnet50, like we have for resnet34 and resnet18. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR9UeMmvpmkV"
   },
   "source": [
    "### Curious what the model architecture looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1613523396725,
     "user": {
      "displayName": "Spandan Madan",
      "photoUrl": "",
      "userId": "18305993989659529139"
     },
     "user_tz": 300
    },
    "id": "Ibdp07pSpmkV",
    "outputId": "0bfec857-fc2a-4381-ccc2-5b1a9bb20d5b"
   },
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SI2cZxkvd8jw"
   },
   "source": [
    "### Anatomy of the ResNet model\n",
    "\n",
    "As you can see above, a ResNet model contains many convolutional layers, ReLU layers and pooling layers, among other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrUbaQqgpmkV"
   },
   "source": [
    "#### Below we have the function which trains, tests and returns the best model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1baRVJnOpmkV"
   },
   "outputs": [],
   "source": [
    "def model_pipeline(model, criterion, optimizer, dset_loaders, dset_sizes, hyperparameters):\n",
    "    with wandb.init(project=\"HARVAR_BAI\", config=hyperparameters):\n",
    "        if hyperparameters['run_name']:\n",
    "            wandb.run.name = hyperparameters['run_name']\n",
    "        config = wandb.config\n",
    "        best_model = model\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        print(config)\n",
    "        \n",
    "        print(config.num_epochs)\n",
    "        for epoch_num in range(config.num_epochs):\n",
    "            wandb.log({\"Current Epoch\": epoch_num})\n",
    "            model = train_model(model, criterion, optimizer, dset_loaders, dset_sizes, config)\n",
    "            best_acc, best_model = val_model(model, best_acc, best_model, dset_loaders, dset_sizes, config)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e7k8r9ypmkW"
   },
   "source": [
    "#### The different steps of the train model function are annotated below inside the function. Read them step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "z_8fxYJ_pmkW"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dset_loaders, dset_sizes, configs):\n",
    "    print('Starting training epoch...')\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    \n",
    "    ### This tells python to track gradients. While testing weights aren't updated hence they are not stored.\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    iters = 0\n",
    "    \n",
    "    \n",
    "    ### We loop over the data loader we created above. Simply using a for loop.\n",
    "    for data in tqdm(dset_loaders['train']):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        ### If you are using a gpu, then script will move the loaded data to the GPU. \n",
    "        ### If you are not using a gpu, ensure that wandb_configs['use_gpu'] is set to False above.\n",
    "        if configs.use_gpu:\n",
    "            inputs = inputs.float().cuda()\n",
    "            labels = labels.long().cuda()\n",
    "        else:\n",
    "            print('WARNING: NOT USING GPU!')\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.long()\n",
    "\n",
    "        \n",
    "        ### We set the gradients to zero, then calculate the outputs, and the loss function. \n",
    "        ### Gradients for this process are automatically calculated by PyTorch.\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "        ### At this point, the program has calculated gradient of loss w.r.t. weights of our NN model.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### optimizer.step() updated the models weights using calculated gradients.\n",
    "        \n",
    "        ### Let's store these and log them using wandb. They will be displayed in a nice online\n",
    "        ### dashboard for you to see.\n",
    "        \n",
    "        iters += 1\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        wandb.log({\"train_running_loss\": running_loss/float(iters*len(labels.data))})\n",
    "        wandb.log({\"train_running_corrects\": running_corrects/float(iters*len(labels.data))})\n",
    "\n",
    "    epoch_loss = float(running_loss) / dset_sizes['train']\n",
    "    epoch_acc = float(running_corrects) / float(dset_sizes['train'])\n",
    "    wandb.log({\"train_accuracy\": epoch_acc})\n",
    "    wandb.log({\"train_loss\": epoch_loss})\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qunChCjtpmkW"
   },
   "outputs": [],
   "source": [
    "def val_model(model, best_acc, best_model, dset_loaders, dset_sizes, configs):\n",
    "    print('Starting testing epoch...')\n",
    "    model.eval() ### tells pytorch to not store gradients as we won't be updating weights while testing.\n",
    "\n",
    "    running_corrects = 0\n",
    "    iters = 0   \n",
    "    for data in tqdm(dset_loaders['val']):\n",
    "        inputs, labels = data\n",
    "        if configs.use_gpu:\n",
    "            inputs = inputs.float().cuda()\n",
    "            labels = labels.long().cuda()\n",
    "        else:\n",
    "            print('WARNING: NOT USING GPU!')\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.long()\n",
    "\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        iters += 1\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        wandb.log({\"train_running_corrects\": running_corrects/float(iters*len(labels.data))})\n",
    "\n",
    "\n",
    "    epoch_acc = float(running_corrects) / float(dset_sizes['val'])\n",
    "\n",
    "    wandb.log({\"test_accuracy\": epoch_acc})\n",
    "    \n",
    "    ### Code is very similar to train set. One major difference, we don't update weights. \n",
    "    ### We only check the performance is best so far, if so, we save this model as the best model so far.\n",
    "    \n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    wandb.log({\"best_accuracy\": best_acc})\n",
    "    \n",
    "    return best_acc, best_model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MTFyOmoL1Tu"
   },
   "source": [
    "# Make sure your runtime is GPU. If you changed your run time, make sure to run your code again from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e669dae80352>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m### Let's run it all, and save the final best model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mbest_final_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdset_loaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwandb_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-b2f594bcb248>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[1;34m(model, criterion, optimizer, dset_loaders, dset_sizes, hyperparameters)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdset_loaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdset_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"HARVAR_BAI\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'run_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'run_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "### Criterion is simply specifying what loss to use. Here we choose cross entropy loss. \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### tells what optimizer to use. There are many options, we here choose Adam.\n",
    "### the main difference between optimizers is that they vary in how weights are updated based on calculated gradients.\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr = wandb_config['base_lr'])\n",
    "\n",
    "if wandb_config['use_gpu']:\n",
    "    criterion.cuda()\n",
    "    model.cuda()\n",
    "    \n",
    "\n",
    "### Creating the folder where our models will be saved.\n",
    "if not os.path.isdir(\"%s/saved_models/\"%wandb_config['git_dir']):\n",
    "    os.mkdir(\"%s/saved_models/\"%wandb_config['git_dir'])\n",
    "    \n",
    "### Let's run it all, and save the final best model.\n",
    "best_final_model = model_pipeline(model, criterion, optimizer_ft, dset_loaders, data_sizes, wandb_config)\n",
    "\n",
    "\n",
    "save_path = '%s/saved_models/%s_final.pt'%(wandb_config['git_dir'], wandb_config['run_name'])\n",
    "with open(save_path,'wb') as F:\n",
    "    torch.save(best_final_model,F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbAT5FJCPONy"
   },
   "source": [
    "# If wandb gives you some unexpected errors above, just run the code below.\n",
    "\n",
    "Sometimes, wandb can run into an error when running on google colab for some reason. This is an active issue that wandb is looking into. So, as a workaround the code below does not rely on wandb, it simply calculates the loss and plots it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "wLNXM8wgY9Zt"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623,
     "referenced_widgets": [
      "3f9ba67334b54454b8da9e6dccab181d",
      "d3ef8f93e04c4febbf923695f2ff3407",
      "119bce08aa9a43129086da787a86636f",
      "bddc3146658540d8b513824fc56436be",
      "dc66cdcdb6f44ceeabffd512f0058d93",
      "41ea2b6ae76347df897e4ab973080a16",
      "d122c1f19cfc4a80bc069d0c1477d63d",
      "0e808fb16b5a4f31a78e34df2e8aba54"
     ]
    },
    "executionInfo": {
     "elapsed": 76460,
     "status": "error",
     "timestamp": 1613523574112,
     "user": {
      "displayName": "Spandan Madan",
      "photoUrl": "",
      "userId": "18305993989659529139"
     },
     "user_tz": 300
    },
    "id": "mwEPrEpRWn3t",
    "outputId": "7d69ad74-53b7-4fc4-8ff6-70b4435e4538"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c290454218fa432fb367aea00c459d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4889ff61cf354a5db194239df8770c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "index = 0\n",
    "for epoch in range(2):\n",
    "    for data in tqdm(dset_loaders['train']):\n",
    "        index += 1\n",
    "        inputs, labels, _ = data\n",
    "        \n",
    "        ### If you are using a gpu, then script will move the loaded data to the GPU. \n",
    "        ### If you are not using a gpu, ensure that wandb_configs['use_gpu'] is set to False above.\n",
    "        if wandb_config['use_gpu']:\n",
    "            inputs = inputs.float().cuda()\n",
    "            labels = labels.long().cuda()\n",
    "        else:\n",
    "            print('WARNING: NOT USING GPU!')\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.long()\n",
    "\n",
    "        \n",
    "        ### We set the gradients to zero, then calculate the outputs, and the loss function. \n",
    "        ### Gradients for this process are automatically calculated by PyTorch.\n",
    "        \n",
    "        optimizer_ft.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "        ### At this point, the program has calculated gradient of loss w.r.t. weights of our NN model.\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        losses.append(loss)\n",
    "        \n",
    "        #if index % 10==0:\n",
    "        #    clear_output()\n",
    "        #    plt.plot(losses)\n",
    "        #    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcxInTMApmkZ"
   },
   "source": [
    "### Congratulations!\n",
    "\n",
    "You just completed your dog vs cats classification! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUC8UOzYpmkZ"
   },
   "source": [
    "# Deliverables for Assignment 2: \n",
    "\n",
    "### Like assignment 1, the delivarables are two fold:\n",
    "\n",
    "Please run this assignment through to the end, and then make two submissions:\n",
    "\n",
    "- Download this notebook as an HTML file. Click File ---> Download as ---> HTML. Submit this on canvas.\n",
    "- Add, commit and push these changes to your github repository."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "bai",
   "language": "python",
   "name": "bai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08216b2975a0470c99039349d96a7744": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0dd6daa2fe824b64a8a49d69b3ba7a16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e808fb16b5a4f31a78e34df2e8aba54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "119bce08aa9a43129086da787a86636f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  4%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41ea2b6ae76347df897e4ab973080a16",
      "max": 1605,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc66cdcdb6f44ceeabffd512f0058d93",
      "value": 60
     }
    },
    "2d28b0b3ca4a4ad996eb5ed3f515e9cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f9ba67334b54454b8da9e6dccab181d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_119bce08aa9a43129086da787a86636f",
       "IPY_MODEL_bddc3146658540d8b513824fc56436be"
      ],
      "layout": "IPY_MODEL_d3ef8f93e04c4febbf923695f2ff3407"
     }
    },
    "41ea2b6ae76347df897e4ab973080a16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "930e6bffa5924460bc99bad111084a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0dd6daa2fe824b64a8a49d69b3ba7a16",
      "placeholder": "​",
      "style": "IPY_MODEL_ace34fab07284f2a83d5c7a0844605c6",
      "value": " 83.3M/83.3M [01:51&lt;00:00, 780kB/s]"
     }
    },
    "93238d035cce43558481cf65d0466943": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab796b059455467285f8baae800aed52",
       "IPY_MODEL_930e6bffa5924460bc99bad111084a25"
      ],
      "layout": "IPY_MODEL_a84f4fc4ff2346c382192a8ca39547e6"
     }
    },
    "a84f4fc4ff2346c382192a8ca39547e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab796b059455467285f8baae800aed52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d28b0b3ca4a4ad996eb5ed3f515e9cb",
      "max": 87306240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08216b2975a0470c99039349d96a7744",
      "value": 87306240
     }
    },
    "ace34fab07284f2a83d5c7a0844605c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bddc3146658540d8b513824fc56436be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e808fb16b5a4f31a78e34df2e8aba54",
      "placeholder": "​",
      "style": "IPY_MODEL_d122c1f19cfc4a80bc069d0c1477d63d",
      "value": " 60/1605 [01:15&lt;25:10,  1.02it/s]"
     }
    },
    "d122c1f19cfc4a80bc069d0c1477d63d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3ef8f93e04c4febbf923695f2ff3407": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc66cdcdb6f44ceeabffd512f0058d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
