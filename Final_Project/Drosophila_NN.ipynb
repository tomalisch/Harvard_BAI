{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMd5XFEMpmkG"
   },
   "source": [
    "<html>\n",
    "<body>\n",
    "    <center> \n",
    "        <h1><u>Drosophila Species Categorizer</u></h1>\n",
    "        <h3> Distinguishes D. mel from D. americanus and D. virilis</h3>\n",
    "    </center>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JLZ79lZUpmkN"
   },
   "outputs": [],
   "source": [
    "### Import general libraries and pytorch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1613522866738,
     "user": {
      "displayName": "Spandan Madan",
      "photoUrl": "",
      "userId": "18305993989659529139"
     },
     "user_tz": 300
    },
    "id": "NBYo9vxspmkN",
    "outputId": "14613e67-2d34-4f1c-ea91-356c893495c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your github directory is :C:/Users/alisc/Documents/GitHub/Harvard_BAI\n"
     ]
    }
   ],
   "source": [
    "### Determine git path ####\n",
    "git_dir = 'C:/Users/alisc/Documents/GitHub/Harvard_BAI'\n",
    "print('Your github directory is :%s'%git_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vSIu5jATTZn7"
   },
   "outputs": [],
   "source": [
    "project_folder = \"%s/Final_Project\"%git_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qBHqiYHSMY9t"
   },
   "outputs": [],
   "source": [
    "os.chdir(project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pw2HumdXpmkP"
   },
   "source": [
    "#### Load model loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1613522873639,
     "user": {
      "displayName": "Spandan Madan",
      "photoUrl": "",
      "userId": "18305993989659529139"
     },
     "user_tz": 300
    },
    "id": "5bU3tVqsFRT_",
    "outputId": "228a8aaf-3844-43b9-f8d3-3d87e227e09e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models are being loaded from: C:\\Users\\alisc\\Documents\\GitHub\\Harvard_BAI\\res\\models\n",
      "Loaders are being loaded from: C:\\Users\\alisc\\Documents\\GitHub\\Harvard_BAI\\res\\loader\n"
     ]
    }
   ],
   "source": [
    "### Making helper code under the folder res available. This includes loaders, models, etc. ###\n",
    "sys.path.append('%s/res/'%git_dir)\n",
    "from models.models import get_model\n",
    "from loader.loader import get_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgpN78WapmkR"
   },
   "source": [
    "### Specifying config for the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_config = {}\n",
    "wandb_config['batch_size'] = 10\n",
    "wandb_config['base_lr'] = 0.01\n",
    "wandb_config['model_arch'] = 'ResNet152'\n",
    "wandb_config['num_classes'] = 3\n",
    "wandb_config['run_name'] = 'Final_Project'\n",
    "\n",
    "### If you are using a CPU, please set wandb_config['use_gpu'] = 0 below. However, if you are using a GPU, leave it unchanged ####\n",
    "wandb_config['use_gpu'] = 1\n",
    "\n",
    "wandb_config['num_epochs'] = 100\n",
    "wandb_config['git_dir'] = git_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdgYVaVppmkR"
   },
   "source": [
    "### Data Loading and Creating Labels Dict ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faqQRpGuTLsd"
   },
   "source": [
    "### Creates file lists for training (50%), validation (30%), and testing (20%) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dDQyNNj627eo"
   },
   "outputs": [],
   "source": [
    "total_paths = {}\n",
    "total_files = {}\n",
    "iterator = 0\n",
    "for path, directories, files in os.walk('%s/data/insect_species/'%project_folder): \n",
    "    if files != []:\n",
    "        total_paths[iterator] = path\n",
    "        total_files[iterator] = files\n",
    "        iterator += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nKleAnDzI94c"
   },
   "outputs": [],
   "source": [
    "total_points = np.array(range(len(total_files)))\n",
    "total_file_paths = {0:[], 1:[], 2:[]}\n",
    "train_file_paths = {0:[], 1:[], 2:[]}\n",
    "val_file_paths = {0:[], 1:[], 2:[]}\n",
    "test_file_paths = {0:[], 1:[], 2:[]}\n",
    "\n",
    "for species in range(len(total_files)):\n",
    "    total_points[species] = len(total_files[species])\n",
    "    for file in range(int(total_points[species]*0.5)):\n",
    "        train_file_paths[species].append(total_paths[species] + '/' + list(total_files[species])[file])\n",
    "        total_file_paths[species].append(total_paths[species] + '/' + list(total_files[species])[file])\n",
    "    for file in range(int(total_points[species]*0.5)+1, int(total_points[species]*0.8)):\n",
    "        val_file_paths[species].append(total_paths[species] + '/' + list(total_files[species])[file])\n",
    "        total_file_paths[species].append(total_paths[species] + '/' + list(total_files[species])[file])\n",
    "    for file in range(int(total_points[species]*0.8)+1, int(total_points[species])):\n",
    "        test_file_paths[species].append(total_paths[species] + '/' + list(total_files[species])[file])\n",
    "        total_file_paths[species].append(total_paths[species] + '/' + list(total_files[species])[file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y93LkDld3J2X"
   },
   "outputs": [],
   "source": [
    "labels_dictionary = {}\n",
    "\n",
    "for species in range(len(total_file_paths)):\n",
    "    for file_path in total_file_paths[species]:\n",
    "        labels_dictionary[file_path] = species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcMXyppD-vsg"
   },
   "source": [
    "Dumps the created labels_dictionary and training, val, and test data file paths for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tz0i23ogApQF"
   },
   "outputs": [],
   "source": [
    "with open('%s/data/labels_dictionary.p'%project_folder, 'wb') as F:\n",
    "    pickle.dump(labels_dictionary, F)\n",
    "\n",
    "with open('%s/data/train_file_list.txt'%project_folder, 'w') as filehandle:\n",
    "    for i in range(3):\n",
    "        for listitem in train_file_paths[i]:\n",
    "            filehandle.write('%s\\n' % listitem)\n",
    "\n",
    "with open('%s/data/val_file_list.txt'%project_folder, 'w') as filehandle:\n",
    "    for i in range(3):\n",
    "        for listitem in val_file_paths[i]:\n",
    "            filehandle.write('%s\\n' % listitem)\n",
    "            \n",
    "with open('%s/data/test_file_list.txt'%project_folder, 'w') as filehandle:\n",
    "    for i in range(3):\n",
    "        for listitem in test_file_paths[i]:\n",
    "            filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-IM8j6vKGTg"
   },
   "source": [
    "# Using a custom data-loader to store image paths, labels, and transforms. \n",
    "\n",
    "Use the 'cats_dogs_loader' for now, mainly a naming issue - the dataset formatting is absolutely fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GMYXrJgn74-P"
   },
   "outputs": [],
   "source": [
    "file_list_loader = get_loader('cats_dogs_loader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BwVYrw4va5OL"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "     'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JO9Oy04kITzd"
   },
   "outputs": [],
   "source": [
    "dsets = {}\n",
    "dsets['train'] = file_list_loader('%s/data/train_file_list.txt'%project_folder, '%s/data/labels_dictionary.p'%project_folder, data_transforms['train'])\n",
    "dsets['val'] = file_list_loader('%s/data/val_file_list.txt'%project_folder, '%s/data/labels_dictionary.p'%project_folder, data_transforms['val'])\n",
    "dsets['test'] = file_list_loader('%s/data/test_file_list.txt'%project_folder, '%s/data/labels_dictionary.p'%project_folder, data_transforms['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kMPWCW6jCHFh"
   },
   "outputs": [],
   "source": [
    "### Above, we created datasets. Now, we will pass them into pytorch's inbuild dataloaders, \n",
    "### these will help us load batches of data for training.\n",
    "dset_loaders = {}\n",
    "dset_loaders['train'] = torch.utils.data.DataLoader(dsets['train'], batch_size=wandb_config['batch_size'], shuffle = True, num_workers=2,drop_last=False)\n",
    "dset_loaders['val'] = torch.utils.data.DataLoader(dsets['val'], batch_size=wandb_config['batch_size'], shuffle = False, num_workers=2,drop_last=False)\n",
    "dset_loaders['test'] = torch.utils.data.DataLoader(dsets['test'], batch_size=wandb_config['batch_size'], shuffle = True, num_workers=2,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PEDTP2GnCUOC"
   },
   "outputs": [],
   "source": [
    "data_sizes = {}\n",
    "data_sizes['train'] = len(dsets['train'])\n",
    "data_sizes['val'] = len(dsets['val'])\n",
    "data_sizes['test'] = len(dsets['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFXtAksGbif_"
   },
   "source": [
    "# Load a ResNet 152 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "93238d035cce43558481cf65d0466943",
      "a84f4fc4ff2346c382192a8ca39547e6",
      "ab796b059455467285f8baae800aed52",
      "930e6bffa5924460bc99bad111084a25",
      "08216b2975a0470c99039349d96a7744",
      "2d28b0b3ca4a4ad996eb5ed3f515e9cb",
      "ace34fab07284f2a83d5c7a0844605c6",
      "0dd6daa2fe824b64a8a49d69b3ba7a16"
     ]
    },
    "executionInfo": {
     "elapsed": 1458,
     "status": "ok",
     "timestamp": 1613523030391,
     "user": {
      "displayName": "Spandan Madan",
      "photoUrl": "",
      "userId": "18305993989659529139"
     },
     "user_tz": 300
    },
    "id": "ZXhnbYKQbhG1",
    "outputId": "ba01cb06-e717-4d0b-a4d8-c7dbc12874f8"
   },
   "outputs": [],
   "source": [
    "### Loads a ResNet model with 152 layers as determined in loaders.py\n",
    "\n",
    "model = get_model('ResNet152', 1000)\n",
    "in_filters = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=in_filters, out_features=wandb_config['num_classes'])\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrUbaQqgpmkV"
   },
   "source": [
    "#### Train, test, and return the best model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1baRVJnOpmkV"
   },
   "outputs": [],
   "source": [
    "def model_pipeline(model, criterion, optimizer, dset_loaders, dset_sizes, hyperparameters):\n",
    "    config = wandb_config\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    for epoch_num in tqdm(range(config['num_epochs'])):\n",
    "        model = train_model(model, criterion, optimizer, dset_loaders, dset_sizes, config)\n",
    "        best_acc, best_model = val_model(model, best_acc, best_model, dset_loaders, dset_sizes, config)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "z_8fxYJ_pmkW"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dset_loaders, dset_sizes, configs):\n",
    "    print('Starting training epoch...')\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    \n",
    "    ### This tells python to track gradients. While testing weights aren't updated hence they are not stored.\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    iters = 0\n",
    "    \n",
    "    \n",
    "    ### We loop over the data loader we created above. Simply using a for loop.\n",
    "    for data in enumerate(dset_loaders['train']):\n",
    "        inputs, labels = data[1][0], data[1][1]\n",
    "        \n",
    "        ### If you are using a gpu, then script will move the loaded data to the GPU. \n",
    "        ### If you are not using a gpu, ensure that wandb_configs['use_gpu'] is set to False above.\n",
    "        if wandb_config['use_gpu']:\n",
    "            inputs = inputs.float().cuda()\n",
    "            labels = labels.long().cuda()\n",
    "        else:\n",
    "            print('WARNING: NOT USING GPU!')\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.long()\n",
    "\n",
    "        \n",
    "        ### We set the gradients to zero, then calculate the outputs, and the loss function. \n",
    "        ### Gradients for this process are automatically calculated by PyTorch.\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "        ### At this point, the program has calculated gradient of loss w.r.t. weights of our NN model.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### optimizer.step() updated the models weights using calculated gradients.\n",
    "        \n",
    "        \n",
    "        iters += 1\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = float(running_loss) / dset_sizes['train']\n",
    "    epoch_acc = float(running_corrects) / float(dset_sizes['train'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qunChCjtpmkW"
   },
   "outputs": [],
   "source": [
    "def val_model(model, best_acc, best_model, dset_loaders, dset_sizes, configs):\n",
    "    print('Starting testing epoch...')\n",
    "    model.eval() ### tells pytorch to not store gradients as we won't be updating weights while testing.\n",
    "\n",
    "    running_corrects = 0\n",
    "    iters = 0   \n",
    "    for data in enumerate(dset_loaders['val']):\n",
    "        inputs, labels = data[1][0], data[1][1]\n",
    "        \n",
    "        if wandb_config['use_gpu']:\n",
    "            inputs = inputs.float().cuda()\n",
    "            labels = labels.long().cuda()\n",
    "        else:\n",
    "            print('WARNING: NOT USING GPU!')\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.long()\n",
    "\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        iters += 1\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "    epoch_acc = float(running_corrects) / float(dset_sizes['val'])\n",
    "   \n",
    "    ### Code is very similar to train set. One major difference, we don't update weights. \n",
    "    ### We only check the performance is best so far, if so, we save this model as the best model so far.\n",
    "    \n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    \n",
    "    return best_acc, best_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e5e41bbfaee6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m### tells what optimizer to use. There are many options, we here choose Adam.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m### the main difference between optimizers is that they vary in how weights are updated based on calculated gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0moptimizer_ft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwandb_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'base_lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwandb_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'use_gpu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "### Criterion is simply specifying what loss to use. Here we choose cross entropy loss. \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### tells what optimizer to use. There are many options, we here choose Adam.\n",
    "### the main difference between optimizers is that they vary in how weights are updated based on calculated gradients.\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr = wandb_config['base_lr'])\n",
    "\n",
    "if wandb_config['use_gpu']:\n",
    "    criterion.cuda()\n",
    "    model.cuda()\n",
    "    \n",
    "\n",
    "### Creating the folder where our models will be saved.\n",
    "if not os.path.isdir(\"%s/saved_models/\"%wandb_config['git_dir']):\n",
    "    os.mkdir(\"%s/saved_models/\"%wandb_config['git_dir'])\n",
    "    \n",
    "### Let's run it all, and save the final best model.\n",
    "best_final_model = model_pipeline(model, criterion, optimizer_ft, dset_loaders, data_sizes, wandb_config)\n",
    "\n",
    "\n",
    "save_path = '%s/saved_models/%s_final.pt'%(wandb_config['git_dir'], wandb_config['run_name'])\n",
    "with open(save_path,'wb') as F:\n",
    "    torch.save(best_final_model,F)\n",
    "print('Best model saved in %s'%save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcxInTMApmkZ"
   },
   "source": [
    "### Save final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: Reload saved model and determine classification accuracy with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08216b2975a0470c99039349d96a7744": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0dd6daa2fe824b64a8a49d69b3ba7a16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e808fb16b5a4f31a78e34df2e8aba54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "119bce08aa9a43129086da787a86636f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  4%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41ea2b6ae76347df897e4ab973080a16",
      "max": 1605,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc66cdcdb6f44ceeabffd512f0058d93",
      "value": 60
     }
    },
    "2d28b0b3ca4a4ad996eb5ed3f515e9cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f9ba67334b54454b8da9e6dccab181d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_119bce08aa9a43129086da787a86636f",
       "IPY_MODEL_bddc3146658540d8b513824fc56436be"
      ],
      "layout": "IPY_MODEL_d3ef8f93e04c4febbf923695f2ff3407"
     }
    },
    "41ea2b6ae76347df897e4ab973080a16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "930e6bffa5924460bc99bad111084a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0dd6daa2fe824b64a8a49d69b3ba7a16",
      "placeholder": "​",
      "style": "IPY_MODEL_ace34fab07284f2a83d5c7a0844605c6",
      "value": " 83.3M/83.3M [01:51&lt;00:00, 780kB/s]"
     }
    },
    "93238d035cce43558481cf65d0466943": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab796b059455467285f8baae800aed52",
       "IPY_MODEL_930e6bffa5924460bc99bad111084a25"
      ],
      "layout": "IPY_MODEL_a84f4fc4ff2346c382192a8ca39547e6"
     }
    },
    "a84f4fc4ff2346c382192a8ca39547e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab796b059455467285f8baae800aed52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d28b0b3ca4a4ad996eb5ed3f515e9cb",
      "max": 87306240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08216b2975a0470c99039349d96a7744",
      "value": 87306240
     }
    },
    "ace34fab07284f2a83d5c7a0844605c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bddc3146658540d8b513824fc56436be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e808fb16b5a4f31a78e34df2e8aba54",
      "placeholder": "​",
      "style": "IPY_MODEL_d122c1f19cfc4a80bc069d0c1477d63d",
      "value": " 60/1605 [01:15&lt;25:10,  1.02it/s]"
     }
    },
    "d122c1f19cfc4a80bc069d0c1477d63d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3ef8f93e04c4febbf923695f2ff3407": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc66cdcdb6f44ceeabffd512f0058d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
